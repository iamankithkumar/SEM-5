{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Normalize data"
      ],
      "metadata": {
        "id": "YUWQkwvGgMhS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abeXHM1LgGx2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def load_and_normalize_data(file_path):\n",
        "    data = pd.read_csv(file_path, header=None)\n",
        "\n",
        "    # Normalize the data using z-score\n",
        "    scaler = StandardScaler()\n",
        "    normalized_data = scaler.fit_transform(data)\n",
        "\n",
        "    return normalized_data\n",
        "\n",
        "#give the required file name to be normalized\n",
        "file_names = ['1.txt']\n",
        "\n",
        "\n",
        "common_data = pd.DataFrame()\n",
        "\n",
        "for file_name in file_names:\n",
        "    file_path = f'/content/drive/MyDrive/S-1/Test/{file_name}'  # Replace with the actual path\n",
        "    normalized_data = load_and_normalize_data(file_path)\n",
        "    common_data = common_data.append(pd.DataFrame(normalized_data), ignore_index=True)\n",
        "\n",
        "# change the name to required file name after normalization\n",
        "common_data.to_csv('/content/drive/MyDrive/S-1/Normal data/S1_2_test_normal.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating a threshold value"
      ],
      "metadata": {
        "id": "giGkaj-7gWa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(file_path, time_steps=10):\n",
        "    data = pd.read_csv(file_path, header=None)\n",
        "    return np.array(data)\n",
        "\n",
        "\n",
        "def calculate_threshold(X_train, model, percentile=95):\n",
        "\n",
        "    reconstructions = model.predict(X_train)\n",
        "    mse = np.mean(np.square(X_train - reconstructions), axis=(1, 2))\n",
        "\n",
        "\n",
        "    threshold = np.percentile(mse, percentile)\n",
        "    return threshold\n",
        "\n",
        "\n",
        "def train_lstm_autoencoder(X_train, epochs=10, batch_size=32):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(RepeatVector(X_train.shape[1]))\n",
        "    model.add(LSTM(units=64, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(X_train.shape[2])))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    model.fit(X_train, X_train, epochs=epochs, batch_size=batch_size)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# give the correct normalized train file path\n",
        "train_file_path = r'/content/drive/MyDrive/S-1/Normal data/S1_3_train_normal.csv'\n",
        "X_train = load_and_preprocess_data(train_file_path)\n",
        "\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "\n",
        "lstm_autoencoder_model = train_lstm_autoencoder(X_train)\n",
        "\n",
        "\n",
        "threshold = calculate_threshold(X_train, lstm_autoencoder_model)\n",
        "\n",
        "print(f\"Threshold: {threshold}\")"
      ],
      "metadata": {
        "id": "cz8oyq_1gtTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the future usage"
      ],
      "metadata": {
        "id": "zfJwVdA8gw-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "import pandas as pd\n",
        "\n",
        "def save_predicted_labels(labels, output_path):\n",
        "    df = pd.DataFrame({'Anomaly': labels})\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(file_path, time_steps=10):\n",
        "    data = pd.read_csv(file_path, header=None)\n",
        "\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_steps + 1):\n",
        "        X.append(data.values[i:i + time_steps, :])\n",
        "        y.append(data.values[i + time_steps - 1, :])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "def detect_anomalies(model, X_test, threshold=0.5):\n",
        "\n",
        "    X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])\n",
        "\n",
        "    reconstructions = model.predict(X_test_reshaped)\n",
        "\n",
        "\n",
        "    mse = np.mean(np.square(X_test_reshaped - reconstructions), axis=(1, 2))\n",
        "\n",
        "\n",
        "    anomalies = (mse > threshold).astype(int)\n",
        "\n",
        "    return anomalies\n",
        "\n",
        "\n",
        "def train_lstm_autoencoder(X_train, epochs=10, batch_size=32):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(RepeatVector(X_train.shape[1]))\n",
        "    model.add(LSTM(units=64, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(X_train.shape[2])))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    model.fit(X_train, X_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    return model\n",
        "\n",
        "# give the correct normalized train file path\n",
        "train_file_path = r'/content/drive/MyDrive/S-1/Normal data/S1_3_train_normal.csv'\n",
        "X_train, y_train = load_and_preprocess_data(train_file_path)\n",
        "\n",
        "# give the correct normalized test file path\n",
        "test_file_path = r'/content/drive/MyDrive/S-1/Normal data/S1_3_test_normal.csv'\n",
        "X_test, y_test = load_and_preprocess_data(test_file_path)\n",
        "\n",
        "\n",
        "lstm_autoencoder_model = train_lstm_autoencoder(X_train)\n",
        "\n",
        "\n",
        "anomalies = detect_anomalies(lstm_autoencoder_model, X_test, threshold=0.443)  # Adjust threshold\n",
        "\n",
        "# Save predicted labels to a CSV file\n",
        "output_csv_path = r'/content/drive/MyDrive/S-1/Pre_lab/3_predicted_labels_lstm.csv'\n",
        "save_predicted_labels(anomalies, output_csv_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XFfnzpFFg3iL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}